{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ihHh75wxm_4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import re\n",
        "import os\n",
        "import fitz  # PyMuPDF for PDF rendering\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------------\n",
        "# You can set this to a single file (image or PDF) or a directory containing\n",
        "# multiple templates for different countries. We'll try them all and pick the best.\n",
        "ID_TEMPLATE_PATH = \"id_template1.pdf\"\n",
        "IMAGE_PATH = \"sample_ids/id_scan4.pdf\" # Change the input image here\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "\n",
        "# OCR Patterns\n",
        "# Default DOB pattern (legacy, using slashes). Country-specific patterns are built via get_dob_pattern().\n",
        "DOB_PATTERN = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
        "# Accept either a simple ID (2 letters + 6 digits) OR PAN format (AAAAA9999A)\n",
        "ID_PATTERN = r\"([A-Z]{2}\\d{6}|[A-Z]{5}\\d{4}[A-Z])\"\n",
        "\n",
        "# Thresholds\n",
        "# Template match threshold on normalized correlation score [0..1]\n",
        "# Lowered slightly to accept more legitimate variation\n",
        "TEMPLATE_MATCH_THRESHOLD = 0.35\n",
        "# Edge ratio threshold (fraction of edge pixels)\n",
        "EDGE_RATIO_THRESHOLD = 0.20\n",
        "# Noise threshold for variance map and the fraction threshold of pixels above it\n",
        "NOISE_VARIANCE_THRESHOLD = 50.0\n",
        "NOISE_FRACTION_THRESHOLD = 0.35\n",
        "\n",
        "# Scoring weights\n",
        "WEIGHT_EDGES = 20\n",
        "WEIGHT_NOISE = 15\n",
        "WEIGHT_OCR = 10\n",
        "WEIGHT_TEMPLATE = 20\n",
        "MAX_SCORE = WEIGHT_EDGES + WEIGHT_NOISE + WEIGHT_OCR + WEIGHT_TEMPLATE\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"edges\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"noise\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"annotated\"), exist_ok=True)\n",
        "\n",
        "# Target normalized size for perspective-warped documents (width, height)\n",
        "WARP_SIZE = (900, 600)\n",
        "\n",
        "# -----------------------------\n",
        "# HELPER FUNCTIONS\n",
        "# -----------------------------\n",
        "def detect_edges(image_gray):\n",
        "    blurred = cv2.GaussianBlur(image_gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blurred, 50, 150)\n",
        "    edge_count = int(np.sum(edges > 0))\n",
        "    h, w = image_gray.shape[:2]\n",
        "    edge_ratio = edge_count / float(h * w)\n",
        "    return edges, edge_count, edge_ratio\n",
        "\n",
        "def save_edge_heatmap(edges, filename=\"edges/edge_heatmap.jpg\"):\n",
        "    heatmap = cv2.applyColorMap(edges, cv2.COLORMAP_JET)\n",
        "    path = os.path.join(OUTPUT_DIR, filename)\n",
        "    cv2.imwrite(path, heatmap)\n",
        "    return path\n",
        "\n",
        "def local_noise_variance(image_gray, ksize=5):\n",
        "    mean = cv2.blur(image_gray.astype(float), (ksize, ksize))\n",
        "    mean_sq = cv2.blur((image_gray.astype(float) ** 2), (ksize, ksize))\n",
        "    variance = mean_sq - mean**2\n",
        "    return variance\n",
        "\n",
        "def save_noise_heatmap(noise_map, filename=\"noise/noise_heatmap.jpg\"):\n",
        "    norm_noise = cv2.normalize(noise_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    heatmap = cv2.applyColorMap(norm_noise, cv2.COLORMAP_JET)\n",
        "    path = os.path.join(OUTPUT_DIR, filename)\n",
        "    cv2.imwrite(path, heatmap)\n",
        "    return path\n",
        "\n",
        "def perform_ocr(image_color):\n",
        "    # Use RGB for better OCR results\n",
        "    if len(image_color.shape) == 3:\n",
        "        rgb = cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB)\n",
        "    else:\n",
        "        rgb = image_color\n",
        "    text = pytesseract.image_to_string(rgb)\n",
        "    return text\n",
        "\n",
        "def check_ocr_fields(text, dob_pattern):\n",
        "    dob_found = bool(re.search(dob_pattern, text))\n",
        "    id_found = bool(re.search(ID_PATTERN, text))\n",
        "    # Be lenient: consider OCR OK if EITHER a DOB OR a valid ID-like string is detected\n",
        "    missing_fields = not (dob_found or id_found)\n",
        "    return missing_fields, dob_found, id_found\n",
        "\n",
        "def highlight_ocr_fields(image, dob_pattern=DOB_PATTERN, id_pattern=ID_PATTERN, filename=\"annotated/ocr_fields.jpg\"):\n",
        "    # Run OCR in RGB for consistency\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image\n",
        "    data = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
        "    img_copy = image.copy()\n",
        "    for i, word in enumerate(data['text']):\n",
        "        x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "        text = data['text'][i]\n",
        "        # Use search instead of fullmatch as OCR tokens are often partial segments\n",
        "        if re.search(dob_pattern, text) or re.search(id_pattern, text):\n",
        "            color = (0, 255, 0)  # Green = valid\n",
        "        else:\n",
        "            color = (0, 0, 255)  # Red = invalid/missing\n",
        "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), color, 2)\n",
        "    annotated_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    cv2.imwrite(annotated_path, img_copy)\n",
        "    return annotated_path, img_copy\n",
        "\n",
        "def _is_image_file(path):\n",
        "    return os.path.splitext(path)[1].lower() in {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp'}\n",
        "\n",
        "def _load_pdf_pages_as_grayscale_images(pdf_path, dpi=200):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pages = []\n",
        "    for page_index in range(len(doc)):\n",
        "        page = doc[page_index]\n",
        "        mat = fitz.Matrix(dpi / 72.0, dpi / 72.0)\n",
        "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
        "        if pix.n == 4:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n",
        "        elif pix.n == 3:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            img = img  # already grayscale\n",
        "        pages.append(img)\n",
        "    doc.close()\n",
        "    return pages\n",
        "\n",
        "def load_template_images(template_path_or_dir=ID_TEMPLATE_PATH, dpi=200):\n",
        "    \"\"\"Load one or more grayscale template images.\n",
        "    - If directory: load all images and PDFs inside (first page of each PDF).\n",
        "    - If file: load as image or all pages if PDF.\n",
        "    Returns list of tuples: (template_name, gray_image)\n",
        "    \"\"\"\n",
        "    templates = []\n",
        "    if template_path_or_dir is None:\n",
        "        return templates\n",
        "    if os.path.isdir(template_path_or_dir):\n",
        "        for fname in sorted(os.listdir(template_path_or_dir)):\n",
        "            fpath = os.path.join(template_path_or_dir, fname)\n",
        "            if os.path.isdir(fpath):\n",
        "                continue\n",
        "            ext = os.path.splitext(fname)[1].lower()\n",
        "            if ext == '.pdf':\n",
        "                pages = _load_pdf_pages_as_grayscale_images(fpath, dpi=dpi)\n",
        "                for i, page in enumerate(pages, start=1):\n",
        "                    templates.append((fname + f\"#p{i}\", page))\n",
        "            elif _is_image_file(fpath):\n",
        "                img = cv2.imread(fpath, 0)\n",
        "                if img is not None:\n",
        "                    templates.append((fname, img))\n",
        "    else:\n",
        "        ext = os.path.splitext(template_path_or_dir)[1].lower()\n",
        "        if ext == '.pdf':\n",
        "            pages = _load_pdf_pages_as_grayscale_images(template_path_or_dir, dpi=dpi)\n",
        "            for i, page in enumerate(pages, start=1):\n",
        "                templates.append((os.path.basename(template_path_or_dir) + f\"#p{i}\", page))\n",
        "        elif _is_image_file(template_path_or_dir):\n",
        "            img = cv2.imread(template_path_or_dir, 0)\n",
        "            if img is not None:\n",
        "                templates.append((os.path.basename(template_path_or_dir), img))\n",
        "    return templates\n",
        "\n",
        "def _order_quad_points(pts):\n",
        "    pts = np.array(pts, dtype=\"float32\")\n",
        "    s = pts.sum(axis=1)\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "    rect[0] = pts[np.argmin(s)]      # top-left\n",
        "    rect[2] = pts[np.argmax(s)]      # bottom-right\n",
        "    rect[1] = pts[np.argmin(diff)]   # top-right\n",
        "    rect[3] = pts[np.argmax(diff)]   # bottom-left\n",
        "    return rect\n",
        "\n",
        "def warp_and_resize(gray_img, target_size=WARP_SIZE):\n",
        "    \"\"\"Find a document-like quad and warp to a fixed size. Fallback to resized image.\"\"\"\n",
        "    try:\n",
        "        img = gray_img.copy()\n",
        "        # Edge detection and contour finding\n",
        "        blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "        edges = cv2.Canny(blurred, 50, 150)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "        quad = None\n",
        "        for cnt in contours[:10]:\n",
        "            peri = cv2.arcLength(cnt, True)\n",
        "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
        "            if len(approx) == 4:\n",
        "                quad = approx.reshape(4, 2)\n",
        "                break\n",
        "        if quad is not None:\n",
        "            rect = _order_quad_points(quad)\n",
        "            (tw, th) = target_size\n",
        "            dst = np.array([[0, 0], [tw-1, 0], [tw-1, th-1], [0, th-1]], dtype=\"float32\")\n",
        "            M = cv2.getPerspectiveTransform(rect, dst)\n",
        "            warped = cv2.warpPerspective(gray_img, M, (tw, th))\n",
        "            return warped\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback: simple resize with preserved aspect into target canvas\n",
        "    tw, th = target_size\n",
        "    h, w = gray_img.shape[:2]\n",
        "    scale = min(tw / w, th / h)\n",
        "    nw, nh = max(1, int(w * scale)), max(1, int(h * scale))\n",
        "    resized = cv2.resize(gray_img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
        "    canvas = np.full((th, tw), 255, dtype=np.uint8)\n",
        "    y0 = (th - nh) // 2\n",
        "    x0 = (tw - nw) // 2\n",
        "    canvas[y0:y0+nh, x0:x0+nw] = resized\n",
        "    return canvas\n",
        "\n",
        "def get_dob_pattern(country: str = \"others\") -> str:\n",
        "    \"\"\"Return a country-specific DOB regex pattern.\n",
        "    - USA: MM--DD--YYYY\n",
        "    - Others: DD--MM--YYYY\n",
        "    Uses double hyphens as separators as per requirement.\n",
        "    \"\"\"\n",
        "    c = (country or \"\").strip().lower()\n",
        "    if c in {\"usa\", \"us\", \"united states\", \"united states of america\"}:\n",
        "        # Month 01-12, Day 01-31, Year 4 digits\n",
        "        return r\"\\b(0[1-9]|1[0-2])--(0[1-9]|[12]\\d|3[01])--\\d{4}\\b\"\n",
        "    # Default to others: Day 01-31, Month 01-12, Year 4 digits\n",
        "    return r\"\\b(0[1-9]|[12]\\d|3[01])--(0[1-9]|1[0-2])--\\d{4}\\b\"\n",
        "\n",
        "def template_match_multi(image_gray, templates, threshold=TEMPLATE_MATCH_THRESHOLD):\n",
        "    \"\"\"Match against multiple templates and return the best match.\n",
        "    templates: list of (name, gray_template)\n",
        "    Returns: (match_ok, best_score, best_name)\n",
        "    \"\"\"\n",
        "    if image_gray is None or not templates:\n",
        "        # No template to compare, don't penalize\n",
        "        return True, 0.0, None\n",
        "    # Normalize both image and templates by warping to a standard canvas\n",
        "    warped_img = warp_and_resize(image_gray, target_size=WARP_SIZE)\n",
        "    best_score = -1.0\n",
        "    best_name = None\n",
        "    for name, template in templates:\n",
        "        if template is None:\n",
        "            continue\n",
        "        warped_tpl = warp_and_resize(template, target_size=WARP_SIZE)\n",
        "        # With equal sizes, matchTemplate yields a single 1x1 response\n",
        "        res = cv2.matchTemplate(warped_img, warped_tpl, cv2.TM_CCOEFF_NORMED)\n",
        "        max_val = float(res[0, 0])\n",
        "        if max_val > best_score:\n",
        "            best_score = max_val\n",
        "            best_name = name\n",
        "    match_ok = bool(best_score >= threshold)\n",
        "    return match_ok, best_score, best_name\n",
        "\n",
        "def analyze_image_arrays(img_color, img_gray, label=\"img\", source=\"image\", dob_pattern=DOB_PATTERN):\n",
        "    tamper_score = 0\n",
        "    results = {}\n",
        "\n",
        "    # Normalize input via perspective warp to reduce layout variance and page noise\n",
        "    working_gray = warp_and_resize(img_gray, target_size=WARP_SIZE)\n",
        "    # Create a pseudo-color version for OCR/annotations\n",
        "    working_color = cv2.cvtColor(working_gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # ---- Edge Analysis ----\n",
        "    edges, edge_count, edge_ratio = detect_edges(working_gray)\n",
        "    edge_path = save_edge_heatmap(edges, filename=f\"edges/edge_heatmap_{label}.jpg\")\n",
        "    results['edges_heatmap'] = edge_path\n",
        "    results['edge_count'] = edge_count\n",
        "    results['edge_ratio'] = round(edge_ratio, 4)\n",
        "    edge_thresh = EDGE_RATIO_THRESHOLD + (0.05 if source == \"pdf\" else 0.0)\n",
        "    if edge_ratio > edge_thresh:\n",
        "        tamper_score += WEIGHT_EDGES\n",
        "        results['edges_flag'] = True\n",
        "    else:\n",
        "        results['edges_flag'] = False\n",
        "\n",
        "    # ---- Noise Analysis ----\n",
        "    noise_map = local_noise_variance(working_gray)\n",
        "    noise_path = save_noise_heatmap(noise_map, filename=f\"noise/noise_heatmap_{label}.jpg\")\n",
        "    results['noise_heatmap'] = noise_path\n",
        "    high_noise_mask = (noise_map > NOISE_VARIANCE_THRESHOLD)\n",
        "    high_noise_area = int(np.sum(high_noise_mask))\n",
        "    h, w = working_gray.shape[:2]\n",
        "    noise_fraction = high_noise_area / float(h * w)\n",
        "    results['noise_fraction'] = round(noise_fraction, 4)\n",
        "    if noise_fraction > NOISE_FRACTION_THRESHOLD:\n",
        "        tamper_score += WEIGHT_NOISE\n",
        "        results['noise_flag'] = True\n",
        "    else:\n",
        "        results['noise_flag'] = False\n",
        "\n",
        "    # ---- OCR + Field Checks ----\n",
        "    ocr_text = perform_ocr(working_color)\n",
        "    missing_fields, dob_found, id_found = check_ocr_fields(ocr_text, dob_pattern)\n",
        "    annotated_path, annotated_img = highlight_ocr_fields(working_color, dob_pattern=dob_pattern, filename=f\"annotated/ocr_fields_{label}.jpg\")\n",
        "    results['ocr_annotated'] = annotated_path\n",
        "    results['ocr_text'] = ocr_text\n",
        "    # If OCR text is very short, don't penalize (could be low-quality scan)\n",
        "    ocr_len = len(ocr_text.strip()) if ocr_text else 0\n",
        "    # Relax OCR penalty for PDFs due to noisy full-page text\n",
        "    min_len = 60 if source == \"pdf\" else 20\n",
        "    if missing_fields and ocr_len >= min_len:\n",
        "        tamper_score += WEIGHT_OCR\n",
        "        results['ocr_flag'] = True\n",
        "    else:\n",
        "        results['ocr_flag'] = False\n",
        "\n",
        "    # ---- Template Matching (multi-template support) ----\n",
        "    templates = load_template_images(ID_TEMPLATE_PATH, dpi=200)\n",
        "    template_ok, template_score, template_name = template_match_multi(img_gray, templates)\n",
        "    results['template_ok'] = template_ok\n",
        "    results['template_score'] = round(template_score, 3)\n",
        "    results['template_name'] = template_name\n",
        "    if not template_ok:\n",
        "        tamper_score += WEIGHT_TEMPLATE\n",
        "        results['template_flag'] = True\n",
        "    else:\n",
        "        results['template_flag'] = False\n",
        "\n",
        "    # ---- Final Tampering Score ----\n",
        "    # Normalize to 0-100\n",
        "    results['tamper_score_raw'] = tamper_score\n",
        "    normalized_score = int(round(100.0 * tamper_score / float(MAX_SCORE))) if MAX_SCORE > 0 else 0\n",
        "\n",
        "    # Compute flags count before finalization\n",
        "    flags_count = int(results['edges_flag']) + int(results['noise_flag']) + int(results['ocr_flag']) + int(results['template_flag'])\n",
        "\n",
        "    # Critical template mismatch override\n",
        "    if (not results['template_ok']) and (results.get('template_score', 0.0) <= 0.12):\n",
        "        normalized_score = 100\n",
        "\n",
        "    results['tamper_score'] = normalized_score\n",
        "    results['flags_count'] = flags_count\n",
        "    results['tamper_warning'] = (normalized_score >= 70) and (flags_count >= 2)\n",
        "\n",
        "    # Print summary for this label\n",
        "    print(f\"\\n=== Tampered Document Analysis ({label}) ===\")\n",
        "    print(f\"Tampering Score: {results['tamper_score']}/100 (raw={results['tamper_score_raw']}/{MAX_SCORE})\")\n",
        "    print(f\"Edge Anomaly: {results['edges_flag']}\")\n",
        "    print(f\"Noise Anomaly: {results['noise_flag']}\")\n",
        "    print(f\"OCR Field Issue: {results['ocr_flag']}\")\n",
        "    if results.get('template_name'):\n",
        "        print(f\"Best Template: {results['template_name']} (score={results['template_score']})\")\n",
        "    print(f\"Template Mismatch: {results['template_flag']}\")\n",
        "    if results['tamper_warning']:\n",
        "        print(\"WARNING: Document potentially tampered!\")\n",
        "    else:\n",
        "        print(\"Document appears normal.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def render_pdf_to_images(pdf_path, dpi=200):\n",
        "    \"\"\"Render each page of a PDF to a BGR image array using PyMuPDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    images = []\n",
        "    for page_index in range(len(doc)):\n",
        "        page = doc[page_index]\n",
        "        mat = fitz.Matrix(dpi / 72.0, dpi / 72.0)\n",
        "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "        # Convert to numpy BGR image\n",
        "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
        "        if pix.n == 4:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n",
        "        elif pix.n == 3:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        else:\n",
        "            # Grayscale\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "        images.append(img)\n",
        "    doc.close()\n",
        "    return images\n",
        "\n",
        "# -----------------------------\n",
        "# MAIN PIPELINE\n",
        "# -----------------------------\n",
        "def analyze_document(image_path=IMAGE_PATH, country: str = \"others\"):\n",
        "    # Build country-specific DOB pattern\n",
        "    dob_pattern = get_dob_pattern(country)\n",
        "    # Handle PDF vs Image paths\n",
        "    ext = os.path.splitext(image_path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        pages = render_pdf_to_images(image_path, dpi=200)\n",
        "        all_results = []\n",
        "        overall = {\n",
        "            'tamper_score': 0,\n",
        "            'tamper_warning': False,\n",
        "            'pages': []\n",
        "        }\n",
        "        for idx, img_color in enumerate(pages, start=1):\n",
        "            label = f\"p{idx}\"\n",
        "            img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "            res = analyze_image_arrays(img_color, img_gray, label=label, source=\"pdf\", dob_pattern=dob_pattern)\n",
        "            all_results.append(res)\n",
        "            overall['pages'].append(res)\n",
        "        # Aggregate: take the max tamper score and warning if any page warns\n",
        "        if all_results:\n",
        "            overall['tamper_score'] = max(r.get('tamper_score', 0) for r in all_results)\n",
        "            overall['tamper_warning'] = any(r.get('tamper_warning', False) for r in all_results)\n",
        "        print(\"\\n=== Overall PDF Analysis Summary ===\")\n",
        "        print(f\"Max Tampering Score across pages: {overall['tamper_score']}\")\n",
        "        print(f\"Any Page Warning: {overall['tamper_warning']}\")\n",
        "        return overall\n",
        "    else:\n",
        "        # Load as standard image\n",
        "        img_gray = cv2.imread(image_path, 0)\n",
        "        img_color = cv2.imread(image_path)\n",
        "        if img_gray is None or img_color is None:\n",
        "            raise FileNotFoundError(f\"Could not read image at path: {image_path}\")\n",
        "        return analyze_image_arrays(img_color, img_gray, label=\"img\", dob_pattern=dob_pattern)\n",
        "\n",
        "# -----------------------------\n",
        "# RUN STANDALONE\n",
        "# -----------------------------\n",
        "if _name_ == \"_main_\":\n",
        "    analyze_document()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
